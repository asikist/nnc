{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIRX: Performance Comparison\n",
    "\n",
    "Here we evaluate how each model performs under fixed interaction intervals.\n",
    "\n",
    "Baseline comparion in terms of total loss and energy.\n",
    "\n",
    "To run this script:\n",
    "1. Please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/sirx/gen_parameters.py```.\n",
    "\n",
    "2. The plots use the training results.\n",
    "Please also make sure that a training proceedures for both RL and NODEC have produced results in the corresponding paths used in plot and table scripts.\n",
    "Running ```nodec_experiments/sirx/nodec_train.ipynb``` and ```nodec_experiments/sirx/nodec_train.ipynb```with default paths is expected to generate at the requiered location for the plots and table scripts in each folder.\n",
    "\n",
    "3. The scripts below:\n",
    " - ```nodec_experiments/sirx/sirx.py```\n",
    " - ```nodec_experiments/sirx/rl_utils.py```\n",
    " - ```nodec_experiments/sirx/sirx_utils.py```\n",
    "contain very important utilities for running training , evaluation and plotting scripts. Please make sure that they are available in the python path when running experiments.\n",
    "\n",
    "Reinforcement Learning requires some significant time to train.\n",
    "\n",
    "As neural network intialization is stochastic, please make sure that appropriate seeds are used or expect some variance to paper results.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "from plotly import figure_factory as ff\n",
    "\n",
    "from sirx import SIRDelta, GCNNControl, flat_to_channels, neighborhood_mask\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "import timeit\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Here we use a custom trajectory evaluator that was used as the basis of the FixedIntervalEvaluator\n",
    "from sirx_utils import trajectory_eval\n",
    "from plotly import express as px\n",
    "\n",
    "\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.helpers.torch_utils.graphs import drivers_to_tensor\n",
    "\n",
    "\n",
    "from sirx import SIRDelta, neighborhood_mask, flat_to_channels, GCNNControl\n",
    "from rl_utils import SIRXEnv, RLGCNN, Actor, Critic, transform_u\n",
    "\n",
    "import tianshou as ts\n",
    "from tianshou.policy import TD3Policy\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.data import Collector, ReplayBuffer, to_torch\n",
    "from tianshou.exploration import GaussianNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and data\n",
    "Plese change to ```'cuda:0'``` to use a gpu or ```'cpu'``` to use the cpu.\n",
    "Here we load the adjacency matrix of a square lattice with $1024$ nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph parameters\n",
    "\n",
    "graph = 'lattice'\n",
    "parameters_folder = '../../../data/parameters/sirx/'\n",
    "training_results_folder = '../../../results/sirx/'+graph+'/'\n",
    "results_folder = '../../../results/sirx/'+graph+'/'\n",
    "\n",
    "graph_parameters_folder = parameters_folder + '/' + 'lattice' + '/'\n",
    "evaluation_results_folder = results_folder + 'eval/'\n",
    "os.makedirs(evaluation_results_folder, exist_ok=True)\n",
    "\n",
    "adjacency_matrix = torch.load(graph_parameters_folder + 'adjacency.pt', map_location=device).to(dtype)\n",
    "n_nodes = adjacency_matrix.shape[-1]\n",
    "drivers = torch.load(graph_parameters_folder + 'drivers.pt', map_location='cpu').to(torch.long)\n",
    "driver_matrix = drivers_to_tensor(n_nodes, drivers).to(dtype=dtype, device=device)\n",
    "alpha = adjacency_matrix\n",
    "beta = driver_matrix\n",
    "side_size = int(np.sqrt(n_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamics Paramters\n",
    "\n",
    "x0 = torch.load(graph_parameters_folder + 'initial_state.pt').to(device=device, dtype=dtype)\n",
    "target_subgraph = torch.load(graph_parameters_folder + 'target_subgraph_nodes.pt')\n",
    "dynamics_params = torch.load(graph_parameters_folder + 'dynamics_parameters.pt')\n",
    "budget = dynamics_params['budget']\n",
    "infection_rate = dynamics_params['infection_rate']\n",
    "recovery_rate = dynamics_params['recovery_rate']\n",
    "total_time = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_interval = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NODEC Evaluation\n",
    "We use the best model observed during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, ninds = neighborhood_mask(alpha)\n",
    "in_preprocessor = lambda x: flat_to_channels(x, n_nodes=n_nodes, mask=mask, inds=ninds)\n",
    "nodec_controller = GCNNControl(alpha, \n",
    "                   beta, \n",
    "                   input_preprocessor=in_preprocessor, \n",
    "                   budget=budget, \n",
    "                   in_channels=4, \n",
    "                   feat_channels=5).to(device=device, dtype=dtype)\n",
    "nodec_controller.load_state_dict(torch.load(training_results_folder + 'nodec_best.pt'))\n",
    "nodec_dynamics = SIRDelta(adjacency_matrix=alpha,\n",
    "                          infection_rate=infection_rate,\n",
    "                          recovery_rate=recovery_rate,\n",
    "                          driver_matrix=beta,\n",
    "                          k_0=0,\n",
    "                         ).to(device=device)\n",
    "\n",
    "all_xnn, all_unn = trajectory_eval(nodec_dynamics, \n",
    "                                   x_0=x0, \n",
    "                                   model = nodec_controller, \n",
    "                                   method='dopri5', \n",
    "                                   T=total_time, \n",
    "                                   dt=interaction_interval\n",
    "                                  )\n",
    "\n",
    "#sanity checks that nodec does not somehow cheat\n",
    "for i in range(all_unn.shape[0]):\n",
    "    assert np.where(all_unn[i]>0)[0].tolist() == drivers.tolist()\n",
    "    assert np.all(all_unn[i]>=0)\n",
    "    assert np.isclose(all_unn[i].sum(), budget) #less or equal also work, but apparently nn is assigning all budget\n",
    "\n",
    "np.save(evaluation_results_folder + 'nodec_states.npy', all_xnn)\n",
    "np.save(evaluation_results_folder + 'nodec_control_signal.npy', all_unn)\n",
    "all_xnn[:, target_subgraph].mean(-1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No control Evaluation\n",
    "Evolution without control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_control_dynamics = SIRDelta(\n",
    "             adjacency_matrix=alpha,\n",
    "             infection_rate=infection_rate,\n",
    "             recovery_rate=recovery_rate,\n",
    "             driver_matrix=beta,\n",
    "             k_0=0\n",
    "            )\n",
    "all_xnc, all_unc = trajectory_eval(no_control_dynamics, \n",
    "                                   x_0=x0, \n",
    "                                   model = None, \n",
    "                                   method='dopri5', \n",
    "                                   T=total_time, \n",
    "                                   dt=interaction_interval\n",
    "                                  )\n",
    "np.save(evaluation_results_folder + 'no_control_states.npy', all_xnc)\n",
    "np.save(evaluation_results_folder + 'no_control_control_signal.npy', all_unc)\n",
    "all_xnc[:, target_subgraph].mean(-1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Control Evaluation\n",
    "We allocate constant control to all driver nodes in target subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find eligible driver nodes inside the target subgraph\n",
    "target_subgraph_drivers = set(target_subgraph.tolist()).intersection(set(drivers.cpu().tolist()))\n",
    "target_subgraph_drivers = sorted(list(target_subgraph_drivers))\n",
    "control = torch.zeros([n_nodes], device=device)\n",
    "control[target_subgraph_drivers] = budget/len(target_subgraph_drivers)\n",
    "\n",
    "constant_control_dynamics = SIRDelta(\n",
    "             adjacency_matrix=alpha,\n",
    "             infection_rate=infection_rate,\n",
    "             recovery_rate=recovery_rate,\n",
    "             driver_matrix=beta,\n",
    "             k_0=control,\n",
    "            )\n",
    "\n",
    "# sanity check that we do the control assignment correctly\n",
    "assert torch.where(control>0)[0].tolist() == target_subgraph_drivers\n",
    "assert torch.all(control>=0)\n",
    "assert torch.isclose(control.sum(), torch.tensor(float(budget)))\n",
    "\n",
    "all_xcc, all_ucc = trajectory_eval(constant_control_dynamics, x_0=x0, model = None, method='dopri5', T=total_time, dt=interaction_interval)\n",
    "all_ucc = control.repeat(int(total_time/interaction_interval)-1, 1)\n",
    "\n",
    "np.save(evaluation_results_folder + 'constant_control_states.npy', all_xcc)\n",
    "np.save(evaluation_results_folder + 'constant_control_signal.npy', all_ucc.cpu().detach().numpy())\n",
    "all_xcc[:, target_subgraph].mean(-1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Control Evaluation\n",
    "We allocate control randomly across nodes per interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_control(x, t, beta, budget):\n",
    "    u = torch.rand([1, n_nodes]).to(device=device)*beta.sum(-1)# (torch.randn([1, n_nodes]).cuda()+10)*beta.sum(-1)\n",
    "    u = budget*(u/u.sum(-1))\n",
    "    return u.to(device=device)\n",
    "\n",
    "\n",
    "random_control_dynamics = SIRDelta(adjacency_matrix=alpha,\n",
    "                                   infection_rate=infection_rate,\n",
    "                                   recovery_rate=recovery_rate,\n",
    "                                   driver_matrix=beta,\n",
    "                                   k_0=0\n",
    "                                  )\n",
    "random_controller = lambda x,t: random_control(x,t, beta=beta, budget=budget)\n",
    "all_xrn, all_urn = trajectory_eval(random_control_dynamics, x_0=x0, model = random_controller, method='dopri5', T=total_time, dt=interaction_interval)\n",
    "all_xnc[:, :n_nodes].mean(-1).max()\n",
    "all_xrn[:, target_subgraph].mean(-1).max()\n",
    "\n",
    "# check if random control somehow managed to cheat\n",
    "for i in range(all_urn.shape[0]):\n",
    "    assert np.where(all_urn[i]>0)[0].tolist() == drivers.cpu().tolist()\n",
    "    assert np.all(all_urn[i]>=0)\n",
    "    assert np.isclose(all_urn[i].sum(), budget)\n",
    "\n",
    "np.save(evaluation_results_folder + 'random_control_states.npy', all_xrn)\n",
    "np.save(evaluation_results_folder + 'random_control_signal.npy', all_urn)\n",
    "all_xrn[:, target_subgraph].mean(-1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Evaluation\n",
    "We use the best model saved during TD3 training, since other methods did not perform that well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask, ninds = neighborhood_mask(alpha)\n",
    "in_preprocessor = lambda x: flat_to_channels(x, n_nodes=n_nodes, mask=mask, inds=ninds)\n",
    "\n",
    "policy_net = RLGCNN(\n",
    "                   adjacency_matrix = alpha,\n",
    "                   driver_matrix = beta, \n",
    "                   input_preprocessor = in_preprocessor,\n",
    "                   in_channels=4,\n",
    "                   feat_channels=5,\n",
    "                   message_passes=4\n",
    "                  )\n",
    "\n",
    "actor = Actor(model = policy_net, device=device).to(device)\n",
    "actor_optim = torch.optim.Adam(actor.parameters(), lr=0.0003)\n",
    "\n",
    "critic1 = Critic(1, 4096, 512, device=device).to(device)\n",
    "critic1_optim = torch.optim.Adam(critic1.parameters(), lr=1e-4)\n",
    "\n",
    "critic2 = Critic(1, 4096, 512, device=device).to(device)\n",
    "critic2_optim = torch.optim.Adam(critic2.parameters(), lr=1e-4)\n",
    "\n",
    "rl_dt = 0.01 # RL interaction frequency\n",
    "\n",
    "rl_dynamics = SIRDelta(adjacency_matrix=alpha,\n",
    "                          infection_rate=infection_rate,\n",
    "                          recovery_rate=recovery_rate,\n",
    "                          driver_matrix=beta,\n",
    "                          k_0=0,\n",
    "                         ).to(device=device)\n",
    "\n",
    "env_config={\n",
    "    'sirx' : rl_dynamics,\n",
    "    'target_nodes' : target_subgraph.tolist(),\n",
    "    'dt' : rl_dt,\n",
    "    'T' : total_time,\n",
    "    'ode_solve_method' : 'dopri5',\n",
    "    'reward_type' : 'sum_to_max',\n",
    "    'x0' : x0,\n",
    "    'budget' : budget    \n",
    "}\n",
    "\n",
    "env = SIRXEnv(env_config)\n",
    "\n",
    "policy = TD3Policy(\n",
    "    actor = actor,\n",
    "    actor_optim = actor_optim,\n",
    "    critic1 = critic1,\n",
    "    critic1_optim = critic1_optim,\n",
    "    critic2 = critic2,\n",
    "    critic2_optim = critic2_optim,\n",
    "    tau= 0.005,\n",
    "    gamma = 0.999,\n",
    "    exploration_noise = GaussianNoise(0.01),\n",
    "    policy_noise = 0.001,\n",
    "    update_actor_freq = 5,\n",
    "    noise_clip = 0.5,\n",
    "    action_range =  [env.action_space.low[0], env.action_space.high[0]],\n",
    "    reward_normalization = True,\n",
    "    ignore_done = False,\n",
    ")\n",
    "\n",
    "policy.load_state_dict(torch.load(training_results_folder + 'rl/td3/time_1608770137/policy.pth'))\n",
    "\n",
    "rl_dynamics = SIRDelta(\n",
    "                 adjacency_matrix=alpha,\n",
    "                 infection_rate=infection_rate,\n",
    "                 recovery_rate=recovery_rate,\n",
    "                 driver_matrix=beta,\n",
    "                 k_0=0,\n",
    "              )\n",
    "\n",
    "model = lambda x,t: transform_u(policy.actor(x)[0], driver_matrix=beta, budget=budget)\n",
    "all_xrl, all_url = trajectory_eval(rl_dynamics, x_0=x0, model =model)\n",
    "np.save(evaluation_results_folder + 'td3_control_states.npy', all_xrl)\n",
    "np.save(evaluation_results_folder + 'td3_control_signal.npy', all_url)\n",
    "all_xrl[:, target_subgraph].mean(-1).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
