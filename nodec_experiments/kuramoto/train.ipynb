{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuramoto: Curriculum Training\n",
    "Below you may find the corresponding trainning proceedure for Kuramoto.\n",
    "This proceedure has been adapted from a script and is expected to fit and produce a NODEC that can control oscillator graphs.\n",
    "\n",
    "Please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/kuramoto/gen_parameters.py```.\n",
    "\n",
    "As neural network intialization is stochastic, please make sure that appropriate seeds are used or expect some variance to paper results.\n",
    "This can be evident as sometimes training does not yield a stable controller.\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when developing\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.controllers.baselines.oscillators.dynamics import AdditiveControlKuramotoDynamics\n",
    "from nnc.controllers.baselines.oscillators.optimal_controllers import KuramotoFeedbackControl\n",
    "\n",
    "from nnc.helpers.torch_utils.graphs import adjacency_tensor, maximum_matching_drivers, drivers_to_tensor\n",
    "from nnc.helpers.torch_utils.oscillators import order_parameter_cos\n",
    "from nnc.helpers.torch_utils.numerics import faster_adj_odeint\n",
    "from nnc.helpers.plot_helper import ColorRegistry, base_layout\n",
    "\n",
    "\n",
    "from tqdm.cli import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Params\n",
    "\n",
    "# Torch params\n",
    "device = 'cuda:0'\n",
    "dtype = torch.float \n",
    "\n",
    "# NODEC Params\n",
    "train = True         # retrain or load pretrained model\n",
    "\n",
    "\n",
    "# Feedback Control Params\n",
    "\n",
    "\n",
    "# Paths\n",
    "data_folder = '../../../data/parameters/kuramoto/'\n",
    "result_folder = '../../../results/kuramoto/'\n",
    "os.makedirs(result_folder, exist_ok = True)\n",
    "\n",
    "graph = 'erdos_renyi'\n",
    "graph_folder = data_folder + graph + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading graph and dynamics parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Parameters for the graph\n",
    "\n",
    "\n",
    "A = torch.load(graph_folder + 'adjacency.pt', map_location=device).float() # adjacency matrix\n",
    "G = nx.from_numpy_matrix(A.numpy())\n",
    "n_nodes = G.number_of_nodes()\n",
    "mean_degree = np.mean(list(dict(G.degree()).values()))\n",
    "\n",
    "A = A.to(device, dtype) # adjacency\n",
    "L = A.sum(-1).diag() - A # laplacian\n",
    "\n",
    "# to save results\n",
    "os.makedirs(graph_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dynamics dependendent variables and states\n",
    "coupling_constants = torch.load(data_folder + 'coupling_constants.pt', map_location=device).to(device, dtype)\n",
    "frustration_constants = torch.load(data_folder + 'frustration_constants.pt', map_location=device).to(device, dtype)\n",
    "natural_frequencies = torch.load(data_folder + 'nominal_angular_velocities.pt', map_location=device).to(device, dtype)\n",
    "K = coupling_constants[2].item() # coupling constant, index 2 should be 0.4\n",
    "frustration_constant = frustration_constants[0] # we use no frustration for this example\n",
    "dynamics_params_folder = graph_folder + 'dynamics_parameters/coupling_' + '{:.1f}'.format(K) + '/'\n",
    "\n",
    "\n",
    "x0 = torch.load(data_folder + 'single_init.pt',  map_location=device)\n",
    "\n",
    "\n",
    "# to avoid using extra memory we load the driver vector \n",
    "# and use element-wise multiplication instead of the driver matrix.\n",
    "gain_vector = torch.load(dynamics_params_folder + 'driver_vector.pt', map_location=device).to(device, dtype)\n",
    "driver_nodes = torch.nonzero(gain_vector).cpu().numpy().flatten().tolist()\n",
    "driver_percentage = len(driver_nodes)/len(gain_vector)\n",
    "steady_state = torch.load(dynamics_params_folder + 'steady_state.pt', map_location=device).to(device, dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Feedback Control Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Controller parameters\n",
    "# Feedback Control\n",
    "feedback_control_constant = 10\n",
    "\n",
    "# Neural Network training\n",
    "n_hidden_units = 3\n",
    "batch_size = 8 # for code ocean GPUs this might be too much, \n",
    "               # reduce to 4 or 2 but stability of learned control may suffer.\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current experiment info:')\n",
    "print('\\t Loaded ' + graph + 'graph with: ' + str(n_nodes) + ' nodes and ' + str(G.number_of_edges()) + ' edges.' )\n",
    "print('\\t Coupling Constant: ' + str(K))\n",
    "print('\\t Frustration Constant: ' + str(frustration_constant.item()))\n",
    "print('\\t Natural Frequencies: mean: ' + str(natural_frequencies.mean().item()) + ' variance: ' + str(natural_frequencies.var().item()) )\n",
    "print('\\t Ratio of driver node vs total nodes: '  + str(len(driver_nodes)/n_nodes))\n",
    "print('\\t Feedback Control Constant: '  + str(feedback_control_constant))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the dynamics:\n",
    "dyn = AdditiveControlKuramotoDynamics(\n",
    "    A, \n",
    "    K, \n",
    "    natural_frequencies,\n",
    "    frustration_constant=frustration_constant\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results without control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a trajectory without control\n",
    "tlin = torch.linspace(0, 150, 500).to(device)\n",
    "state_trajectory_noc = odeint(lambda t,y: dyn(t,y,u=None),x0, tlin, method='dopri5')\n",
    "y=order_parameter_cos(state_trajectory_noc.squeeze().cpu())\n",
    "fig_noc = px.line(y=y.cpu().numpy(), x=tlin.cpu().numpy())\n",
    "fig_noc.data[0].name = 'No control'\n",
    "fig_noc.data[0].line.color = ColorRegistry.constant\n",
    "fig_noc.data[0].showlegend = True\n",
    "fig_noc.layout.xaxis.title.text = 'Time'\n",
    "fig_noc.layout.yaxis.title.text = '$r(t)$'\n",
    "fig_noc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with feedback control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating feecback control trajectory\n",
    "cont = lambda x: feedback_control_constant*gain_vector*torch.sin(-x)\n",
    "state_trajectory_oc = odeint(lambda t,y: dyn(t,y.detach(),u=cont(y).detach()), \n",
    "            x0,\n",
    "            torch.linspace(0, 150, 500).to(device), \n",
    "            method='dopri5'\n",
    "           )\n",
    "y=order_parameter_cos(state_trajectory_oc.squeeze().cpu())\n",
    "fig_fc = px.line(y=y.cpu().numpy(), x=torch.linspace(0, 150, 500).numpy())\n",
    "fig_fc = px.line(y=y.cpu().numpy(), x=tlin.cpu().numpy())\n",
    "fig_fc.data[0].name = 'Feedback Control'\n",
    "fig_fc.data[0].line.color = ColorRegistry.oc\n",
    "fig_fc.data[0].showlegend = True\n",
    "fig_fc.layout.xaxis.title.text = 'Time'\n",
    "fig_fc.layout.yaxis.title.text = '$r(t)$'\n",
    "fig_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NODEC\n",
    "Since we developed Kuramoto recently, we choose to provide the curriculum learning and the architecture in the notebook.\n",
    "After unit testing we will include it in the main library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedback control neural network\n",
    "class EluFeedbackControl(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Very simple Elu architecture for control of linear systems\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes, n_drivers, driver_matrix, n_hidden=3):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(n_nodes,n_hidden)\n",
    "        self.linear_h1 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_final = torch.nn.Linear(n_hidden, n_drivers)\n",
    "        self.driver_matrix = driver_matrix\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        :param t: A scalar or a batch with scalars\n",
    "        :param x: input_states for all nodes\n",
    "        :return:\n",
    "        \"\"\"     \n",
    "        u = self.linear(torch.sin(x))\n",
    "        u = torch.nn.functional.elu(u)\n",
    "        u = self.linear_h1(u)\n",
    "        u = torch.nn.functional.elu(u)\n",
    "        u = self.linear_final(u)\n",
    "        # we multiply by the nn driver matrix to generate the control signal\n",
    "        u = (self.driver_matrix@u.unsqueeze(-1)).squeeze(-1)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert the driver vector back to a matrix \n",
    "# and convert the non-zero elements to 1, so that the neural network is agnostic of the exact gain values.\n",
    "driver_matrix = drivers_to_tensor(A.shape[-1], driver_nodes).to(dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set a seed for NN weight generation to try to make results as reproducible as possible:\n",
    "torch.manual_seed(3548)\n",
    "neural_net = EluFeedbackControl(n_nodes,\n",
    "                                len(driver_nodes), \n",
    "                                driver_matrix,\n",
    "                                n_hidden=n_hidden_units\n",
    "                               ).to(dtype=dtype, device=device)\n",
    "\n",
    "for param, dat in neural_net.named_parameters():\n",
    "    if 'bias' not in param:\n",
    "        torch.nn.init.xavier_normal_(dat)\n",
    "        # we initialize close to 0 to avoid learning high energy solutions\n",
    "        dat = dat/1000\n",
    "nnc_dyn = NNCDynamics(dyn, neural_net).to(dtype=dtype, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(neural_net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training with curriculum\n",
    "Please notice how the batch trainning and curriculum learning proceedures operate on lines 8 and 24 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    pbar = tqdm(range(epochs))\n",
    "    trajectory_length = [1]\n",
    "    for i in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "        def closure():\n",
    "            # sample new minibatch for training\n",
    "            sample = torch.randn([batch_size, 1, n_nodes]).to(device)\n",
    "            state_samples = 100\n",
    "            x_reached = faster_adj_odeint(nnc_dyn, \n",
    "                                          sample,\n",
    "                                          torch.linspace(0,\n",
    "                                                         trajectory_length[0],\n",
    "                                                         state_samples).to(device), \n",
    "                                       method='dopri5', \n",
    "                               #adjoint_params=neural_net.parameters()\n",
    "                              )[1:]        \n",
    "\n",
    "            op = order_parameter_cos(x_reached)\n",
    "            loss =  (-op.mean(-1) - op.min(-1).values).mean()       \n",
    "            loss.backward()\n",
    "            loss_value = loss.item()\n",
    "            pbar.set_postfix({'Training loss: ' :  str(round(loss_value,2)) ,  \n",
    "                              'trajectory length in time units: ' : str(round(trajectory_length[0], 2))})\n",
    "            # increase trajectory by sampling a uniform distribution in [0,2]\n",
    "            trajectory_length[0] = trajectory_length[0]+2*torch.rand(1).item()\n",
    "            return loss.item()\n",
    "        \n",
    "\n",
    "        try:\n",
    "            optimizer.step(closure)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    torch.save(neural_net.state_dict(), result_folder + 'trained_model.pt')\n",
    "else: \n",
    "    neural_net.load_state_dict(torch.load( '../../../data/parameters/kuramoto/erdos_renyi/trained_model.pt',  \n",
    "                                          map_location=device)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neural_net.state_dict(), result_folder + 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "tlin = torch.linspace(0, 150, 500).to(device)\n",
    "state_trajectory_nn = odeint( lambda t,y: dyn(t,y.detach(),u=nnc_dyn.nnc.neural_net(t, y.detach())), \n",
    "            x0,\n",
    "            tlin, method='dopri5',\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NODEC Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = order_parameter_cos(state_trajectory_nn.cpu().detach())\n",
    "\n",
    "px.line(y=y.cpu().numpy().flatten(), x = tlin.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
