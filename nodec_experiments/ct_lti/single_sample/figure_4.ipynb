{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT-LTI: Figure 4.\n",
    "These are the plots found in Figures 4a, 4b and 4c and containing training metrics over epochs.\n",
    "\n",
    "Please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/ct_lti/gen_parameters.py```.\n",
    "\n",
    "Please also make sure that a training and an evaluation proceedures has produced results in the corresponding paths used below.\n",
    "Running ```nodec_experiments/ct_lti/single_sample/train.ipynb``` and \n",
    "```nodec_experiments/ct_lti/single_sample/figure_4_evaluate.ipynb```\n",
    "with default paths is expected to generate at the required location.\n",
    "\n",
    "As neural network intialization is stochastic, please make sure that appropriate seeds are used or expect some variance to paper results.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../../../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.cli import tqdm\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "from nnc.controllers.baselines.ct_lti.dynamics import ContinuousTimeInvariantDynamics\n",
    "from nnc.controllers.baselines.ct_lti.optimal_controllers import ControllabiltyGrammianController\n",
    "\n",
    "from nnc.helpers.torch_utils.graphs import adjacency_tensor, drivers_to_tensor\n",
    "from nnc.helpers.graph_helper import load_graph\n",
    "from nnc.helpers.torch_utils.evaluators import FixedInteractionEvaluator\n",
    "from nnc.helpers.torch_utils.losses import FinalStepMSE\n",
    "from nnc.helpers.torch_utils.trainers import NODECTrainer\n",
    "from nnc.helpers.torch_utils.file_helpers import read_tensor_from_collection\n",
    "\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.helpers.torch_utils.nn_architectures.fully_connected import StackedDenseTimeControl\n",
    "from nnc.helpers.plot_helper import base_layout, sci_notation, ColorRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample and parameters\n",
    "Here we load the sample that we trained NODEC on as well as the parameters for the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "graph='lattice'\n",
    "\n",
    "# load graph data\n",
    "experiment_data_folder = '../../../../data/parameters/ct_lti/'\n",
    "results_data_folder = '../../../../data/results/ct_lti/single_sample/'\n",
    "\n",
    "graph_folder = experiment_data_folder+graph+'/'\n",
    "adj_matrix = torch.load(graph_folder+'adjacency.pt').to(dtype=torch.float, device=device)\n",
    "n_nodes = adj_matrix.shape[0]\n",
    "drivers = torch.load(graph_folder + 'drivers.pt')\n",
    "n_drivers = len(drivers)\n",
    "pos = pd.read_csv(graph_folder + 'pos.csv').set_index('index').values\n",
    "driver_matrix = drivers_to_tensor(n_nodes, drivers).to(device)\n",
    "\n",
    "\n",
    "target_states = torch.load(graph_folder+'target_states.pt').to(device)\n",
    "initial_states = torch.load(experiment_data_folder+'init_states.pt').to(device)\n",
    "\n",
    "current_sample_id = 24\n",
    "\n",
    "x0 = initial_states[current_sample_id].unsqueeze(0)\n",
    "xstar = target_states[current_sample_id].unsqueeze(0)\n",
    "\n",
    "# total time for control\n",
    "\n",
    "total_time=0.5\n",
    "\n",
    "# select dynamics type and initial-target states\n",
    "\n",
    "dyn = ContinuousTimeInvariantDynamics(adj_matrix, driver_matrix)\n",
    "\n",
    "# Below is a helper function that loads parameters from a specific epoch and uses them to evaluate.\n",
    "def check_for_params(params, n_interactions, logdir=None, epoch=0):\n",
    "    nn = StackedDenseTimeControl(n_nodes, \n",
    "                                 n_drivers, \n",
    "                                 n_hidden=0, \n",
    "                                 hidden_size=15,\n",
    "                                 activation=torch.nn.functional.elu,\n",
    "                                 use_bias=True\n",
    "                                ).to(x0.device)\n",
    "\n",
    "    nndyn = NNCDynamics(dyn, nn).to(x0.device)\n",
    "    nndyn.nnc.load_state_dict(params)\n",
    "\n",
    "\n",
    "    loss_fn = FinalStepMSE(xstar, total_time=total_time)\n",
    "\n",
    "    nn_evaluator = FixedInteractionEvaluator(\n",
    "        'early_eval_nn_sample_ninter_' + str(n_interactions),\n",
    "        log_dir=logdir,\n",
    "        n_interactions=n_interactions,\n",
    "        loss_fn=loss_fn,\n",
    "        ode_solver=None,\n",
    "        ode_solver_kwargs={'method' : 'dopri5'},\n",
    "        preserve_intermediate_states=False,\n",
    "        preserve_intermediate_controls=False,\n",
    "        preserve_intermediate_times=False,\n",
    "        preserve_intermediate_energies=False,\n",
    "        preserve_intermediate_losses=False,\n",
    "        preserve_params=False,\n",
    "    )\n",
    "    nn_res = nn_evaluator.evaluate(dyn, nndyn.nnc, x0, total_time, epoch=epoch)\n",
    "    return nn_evaluator, nn_res\n",
    "\n",
    "all_epochs = pd.read_csv(results_data_folder + 'nn_sample_train/epoch_metadata.csv')['epoch']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generating Figure 4a.\n",
    "For this figure we first need to load all stored parameters per epoch and evaluate them for all 3 different interaction intervals $10^{-2}, 10^{-3}, 10^{-4}$. Since this is a costly operation, we can also choose to reload an existing file if there is one. \n",
    "\n",
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_df = pd.read_csv(results_data_folder + 'nn_sample_train/losses_interactions_training.csv',\n",
    "                        engine='python')\n",
    "for i, column in enumerate(losses_df.columns):\n",
    "    if i  >0:\n",
    "        losses_df.columns.values[i] = int(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please check here if columns need to be string or int, different pandas version return different outcomes\n",
    "losses_melted = losses_df.reset_index().melt(id_vars='Epoch', value_vars=[50,500,5000], \n",
    "                                             var_name='Interaction Interval',\n",
    "                                             value_name = 'Total Loss')\n",
    "# From total interactions to interval\n",
    "losses_melted['Interaction Interval'] = total_time/losses_melted['Interaction Interval'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_melted['Interaction Interval'] = losses_melted['Interaction Interval'].map(lambda x: sci_notation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = results_data_folder + 'nn_sample_train/'\n",
    "evaluation_files =  dict(oc_50 = results_data_folder + 'oc_sample_ninter_50/',\n",
    "                         oc_500 = results_data_folder + 'oc_sample_ninter_500/',\n",
    "                         oc_5000 = results_data_folder + 'oc_sample_ninter_5000/',\n",
    "                         nodec_50 = results_data_folder + 'eval_nn_sample_ninter_50/',\n",
    "                         nodec_500 = results_data_folder + 'eval_nn_sample_ninter_500/',\n",
    "                         nodec_5000 = results_data_folder + 'eval_nn_sample_ninter_5000/',\n",
    "                         )\n",
    "\n",
    "oc_500_df = pd.read_csv(evaluation_files['oc_500'] + 'epoch_metadata.csv')\n",
    "nn_500_df = pd.read_csv(evaluation_files['nodec_500'] + 'epoch_metadata.csv')\n",
    "oc_500_loss_val = oc_500_df['final_loss'].values[0]\n",
    "oc_500_energy_val = oc_500_df['total_energy'].values[0]\n",
    "\n",
    "df_training = pd.read_csv(train_file+'/epoch_metadata.csv')\n",
    "epoch_range = [df_training['epoch'].min(), df_training['epoch'].max()]\n",
    "\n",
    "\n",
    "nodec_500_loss = px.line(df_training[['total_energy', 'epoch', 'final_loss']], x='epoch', y='final_loss').data[0]\n",
    "nodec_500_loss.name = 'NODEC Loss'\n",
    "\n",
    "\n",
    "\n",
    "nodec_500_loss = px.line(df_training[['epoch', 'final_loss']], x='epoch', y='final_loss').data[0]\n",
    "nodec_500_loss.line.color = ColorRegistry.nodec\n",
    "nodec_500_loss.name = 'NODEC Loss'\n",
    "nodec_500_loss.showlegend = True\n",
    "\n",
    "oc_500_loss = px.line(x=epoch_range, y=[oc_500_loss_val, oc_500_loss_val]).data[0]\n",
    "oc_500_loss.name = 'OC Loss'\n",
    "oc_500_loss.line.color = ColorRegistry.oc\n",
    "oc_500_loss.showlegend = True\n",
    "\n",
    "nodec_500_energy = px.line(df_training[['total_energy', 'epoch', 'final_loss']], x='epoch', y='total_energy').data[0]\n",
    "nodec_500_energy.line.color = ColorRegistry.nodec\n",
    "nodec_500_energy.name = 'NODEC Energy'\n",
    "nodec_500_energy.showlegend = True\n",
    "nodec_500_energy.line.dash = 'dot'\n",
    "\n",
    "oc_500_energy = px.line(x=epoch_range, y=[oc_500_energy_val, oc_500_energy_val]).data[0]\n",
    "oc_500_energy.name = 'OC Energy'\n",
    "oc_500_energy.line.dash = 'dot'\n",
    "oc_500_energy.line.color = ColorRegistry.oc\n",
    "oc_500_energy.showlegend = True\n",
    "\n",
    "\n",
    "fig_epoch_comparison = plotly.subplots.make_subplots(1,1, specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig_epoch_comparison.add_trace(nodec_500_energy, secondary_y=True)\n",
    "fig_epoch_comparison.add_trace(oc_500_energy, secondary_y=True)\n",
    "\n",
    "fig_epoch_comparison.add_trace(nodec_500_loss)\n",
    "fig_epoch_comparison.add_trace(oc_500_loss)\n",
    "\n",
    "fig_epoch_comparison.update_layout(base_layout)\n",
    "fig_epoch_comparison.update_yaxes(type='log', exponentformat='power', showgrid=False)\n",
    "fig_epoch_comparison.update_layout(#width=240, \n",
    "                                   #height=180,\n",
    "                                   width = 210,\n",
    "                                   height=210,\n",
    "                                   margin = dict(t=50,b=0,l=0,r=20), \n",
    "                                   legend=dict(\n",
    "                                        orientation=\"h\",\n",
    "                                  x=0.0,\n",
    "                                  y=1.4,                                \n",
    "                                  bgcolor=\"rgba(0,0,0,0)\",\n",
    "                                  bordercolor=\"Black\",\n",
    "                                  borderwidth=0\n",
    "                                )\n",
    "\n",
    "                                  )\n",
    "fig_epoch_comparison.layout.yaxis.title = 'Final Loss'\n",
    "fig_epoch_comparison.layout.yaxis2.title = 'Total Energy'\n",
    "fig_epoch_comparison.layout.xaxis.title = 'Epoch'\n",
    "\n",
    "fig_epoch_comparison.layout.yaxis.exponentformat = 'SI'\n",
    "fig_epoch_comparison.layout.yaxis.nticks = 7\n",
    "\n",
    "fig_epoch_comparison.update_layout(width=400, height=300)\n",
    "\n",
    "fig_epoch_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Figure 4b\n",
    "For this figure we collect all loss and energy values for $10^{-3}$ interaction interval time per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_squared_norms = []\n",
    "for epoch in tqdm(all_epochs):\n",
    "    params = read_tensor_from_collection(results_data_folder + 'nn_sample_train/' + 'epochs', 'nodec_params/ep_'+str(epoch)+'.pt')\n",
    "    squared_norm = sum([(param**2).sum().item() for param in params.values()])\n",
    "    param_squared_norms.append(squared_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcolors = np.array(plotly.colors.qualitative.Dark24)\n",
    "vcolors = [col.replace('rgb', 'rgba').replace(')', ',0.3)') for col in vcolors]\n",
    "\n",
    "fig = px.line(y=param_squared_norms, x=losses_df.index)\n",
    "fig.data[0].line.color = vcolors[0]\n",
    "fig.layout.xaxis.title = 'Epoch'\n",
    "fig.layout.yaxis.title = r'$||w||_2^2$'\n",
    "\n",
    "fig.update_layout(base_layout)\n",
    "fig.update_layout(width=160, height=160, margin = dict(t=0,b=20,l=20,r=0), \n",
    "                                  legend=dict(\n",
    "                                        orientation=\"h\",\n",
    "                                  font = dict(size=8),\n",
    "                                  x=0,\n",
    "                                  y=1.35,                                \n",
    "                                  bgcolor=\"rgba(0,0,0,0)\",\n",
    "                                  bordercolor=\"Black\",\n",
    "                                  borderwidth=0,\n",
    "                                      title = dict(side = 'top')\n",
    "                                  )\n",
    "                                )\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(width=400, height=300)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Figure 4c\n",
    "The figure that shows loss values per interaction interval for NODEC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(losses_melted, x='Epoch', y='Total Loss', color='Interaction Interval', log_y=True, \n",
    "              color_discrete_sequence=vcolors, render_mode='svg')\n",
    "fig.update_layout(base_layout)\n",
    "#fig.data[0].line.dash = 'dot'\n",
    "#fig.data[1].line.dash = 'dot'\n",
    "fig.data[2].line.dash = 'dot'\n",
    "fig.update_yaxes(exponentformat='power')\n",
    "fig.update_layout(width=160, height=195, margin = dict(t=35,b=0,l=0,r=0), \n",
    "                                  legend=dict(\n",
    "                                        orientation=\"h\",\n",
    "                                  font = dict(size=8),\n",
    "                                  x=0,\n",
    "                                  y=1.45,                                \n",
    "                                  bgcolor=\"rgba(0,0,0,0)\",\n",
    "                                  bordercolor=\"Black\",\n",
    "                                  borderwidth=0,\n",
    "                                      title = dict(side = 'top')\n",
    "                                  )\n",
    "                                )\n",
    "\n",
    "fig.layout.yaxis.tickfont = dict(size=9)\n",
    "fig.layout.yaxis.nticks = 7\n",
    "fig.layout.yaxis.tickmode = 'auto'\n",
    "\n",
    "fig.layout.yaxis.exponentformat = 'SI'\n",
    "\n",
    "fig.update_layout(width=400, height=300)\n",
    "fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
