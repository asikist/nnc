{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT-LTI: Figure 4: Generate Evaluation Data\n",
    "For Figure 4 some data need to be generate after training to calculate metrics over epochs.\n",
    "Please run this script to recalculate the evaluation if you do not use the provided results.\n",
    "\n",
    "Please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/ct_lti/gen_parameters.py```.\n",
    "\n",
    "Please also make sure that a training proceedure has produced results in the corresponding paths used below.\n",
    "Running ```nodec_experiments/ct_lti/single_sample/train.ipynb``` with default paths is expected to generate at the requiered location.\n",
    "\n",
    "As neural network intialization is stochastic, please make sure that appropriate seeds are used or expect some variance to paper results.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../../../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.cli import tqdm\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "from nnc.controllers.baselines.ct_lti.dynamics import ContinuousTimeInvariantDynamics\n",
    "from nnc.controllers.baselines.ct_lti.optimal_controllers import ControllabiltyGrammianController\n",
    "\n",
    "from nnc.helpers.torch_utils.graphs import adjacency_tensor, drivers_to_tensor\n",
    "from nnc.helpers.graph_helper import load_graph\n",
    "from nnc.helpers.torch_utils.evaluators import FixedInteractionEvaluator\n",
    "from nnc.helpers.torch_utils.losses import FinalStepMSE\n",
    "from nnc.helpers.torch_utils.trainers import NODECTrainer\n",
    "from nnc.helpers.torch_utils.file_helpers import read_tensor_from_collection\n",
    "\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.helpers.torch_utils.nn_architectures.fully_connected import StackedDenseTimeControl\n",
    "from nnc.helpers.plot_helper import base_layout, sci_notation, ColorRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample and parameters\n",
    "Here we load the sample that we trained NODEC on as well as the parameters for the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "graph='lattice'\n",
    "\n",
    "# load graph data\n",
    "experiment_data_folder = '../../../../data/parameters/ct_lti/'\n",
    "\n",
    "# training results are expected to already have been produced and moved to the data folder.\n",
    "training_results_data_folder = '../../../../results/ct_lti/single_sample/'\n",
    "\n",
    "\n",
    "results_data_folder = '../../../../results/ct_lti/single_sample/'\n",
    "\n",
    "os.makedirs(results_data_folder, exist_ok=True)\n",
    "\n",
    "graph_folder = experiment_data_folder+graph+'/'\n",
    "adj_matrix = torch.load(graph_folder+'adjacency.pt').to(dtype=torch.float, device=device)\n",
    "n_nodes = adj_matrix.shape[0]\n",
    "drivers = torch.load(graph_folder + 'drivers.pt')\n",
    "n_drivers = len(drivers)\n",
    "pos = pd.read_csv(graph_folder + 'pos.csv').set_index('index').values\n",
    "driver_matrix = drivers_to_tensor(n_nodes, drivers).to(device)\n",
    "\n",
    "\n",
    "target_states = torch.load(graph_folder+'target_states.pt').to(device)\n",
    "initial_states = torch.load(experiment_data_folder+'init_states.pt').to(device)\n",
    "\n",
    "current_sample_id = 24\n",
    "\n",
    "x0 = initial_states[current_sample_id].unsqueeze(0)\n",
    "xstar = target_states[current_sample_id].unsqueeze(0)\n",
    "\n",
    "# total time for control\n",
    "\n",
    "total_time=0.5\n",
    "\n",
    "# select dynamics type and initial-target states\n",
    "\n",
    "dyn = ContinuousTimeInvariantDynamics(adj_matrix, driver_matrix)\n",
    "\n",
    "# Below is a helper function that loads parameters from a specific epoch and uses them to evaluate.\n",
    "def check_for_params(params, n_interactions, logdir=None, epoch=0):\n",
    "    nn = StackedDenseTimeControl(n_nodes, \n",
    "                                 n_drivers, \n",
    "                                 n_hidden=0, \n",
    "                                 hidden_size=15,\n",
    "                                 activation=torch.nn.functional.elu,\n",
    "                                 use_bias=True\n",
    "                                ).to(x0.device)\n",
    "\n",
    "    nndyn = NNCDynamics(dyn, nn).to(x0.device)\n",
    "    nndyn.nnc.load_state_dict(params)\n",
    "\n",
    "\n",
    "    loss_fn = FinalStepMSE(xstar, total_time=total_time)\n",
    "\n",
    "    nn_evaluator = FixedInteractionEvaluator(\n",
    "        'early_eval_nn_sample_ninter_' + str(n_interactions),\n",
    "        log_dir=logdir,\n",
    "        n_interactions=n_interactions,\n",
    "        loss_fn=loss_fn,\n",
    "        ode_solver=None,\n",
    "        ode_solver_kwargs={'method' : 'dopri5'},\n",
    "        preserve_intermediate_states=False,\n",
    "        preserve_intermediate_controls=False,\n",
    "        preserve_intermediate_times=False,\n",
    "        preserve_intermediate_energies=False,\n",
    "        preserve_intermediate_losses=False,\n",
    "        preserve_params=False,\n",
    "    )\n",
    "    nn_res = nn_evaluator.evaluate(dyn, nndyn.nnc, x0, total_time, epoch=epoch)\n",
    "    return nn_evaluator, nn_res\n",
    "\n",
    "all_epochs = pd.read_csv(training_results_data_folder + 'nn_sample_train/epoch_metadata.csv')['epoch']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generating Data\n",
    "For this figure we first need to load all stored parameters per epoch and evaluate them for all 3 different interaction intervals $10^{-2}, 10^{-3}, 10^{-4}$. Since this is a costly operation, we can also choose to reload an existing file if there is one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we calculate the loss and energy values per epoch by using the evaluator. \n",
    "# This is expected to be a slow calculation.\n",
    "loss_50  = [] \n",
    "loss_500 =[]\n",
    "loss_5000 = []\n",
    "\n",
    "for epoch in tqdm(all_epochs):\n",
    "    params = read_tensor_from_collection(training_results_data_folder + 'nn_sample_train/' + 'epochs', 'nodec_params/ep_'+str(epoch)+'.pt')\n",
    "    loss_50.append(check_for_params(params, 50)[1]['final_loss'])\n",
    "    loss_500.append(check_for_params(params, 500)[1]['final_loss'])\n",
    "    loss_5000.append(check_for_params(params, 5000)[1]['final_loss'])\n",
    "\n",
    "losses_df = pd.DataFrame({\n",
    "    50 : torch.stack(loss_50).cpu().detach().numpy(),\n",
    "    500 :  torch.stack(loss_500).cpu().detach().numpy(),\n",
    "    5000 :  torch.stack(loss_5000).cpu().detach().numpy()    \n",
    "}, index = pd.Series(all_epochs, name='Epoch'))\n",
    "\n",
    "losses_df.to_csv(results_data_folder + 'nn_sample_train/losses_interactions_training.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
